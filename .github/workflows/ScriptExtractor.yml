# This is a basic workflow to help you get started with Actions

name: Add script to Git

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    env:
      SNOWSQL_PWD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      SNOWSQL_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWSQL_USER: ${{ secrets.SNOWFLAKE_USERNAME }}
      SNOWSQL_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWSQL_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
      SNOWSQL_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWSQL_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install Snowflake Connector for Python
        run: pip install snowflake-connector-python[pandas]

      - name: Run Snowflake query and write to file in specified folder
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USERNAME }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          python -c "
          import snowflake.connector
          import pandas as pd
          import os
          # Connect to Snowflake
          conn = snowflake.connector.connect(
              user='${{ secrets.SNOWFLAKE_USER }}',
              password='${{ secrets.SNOWFLAKE_PASSWORD }}',
              account='${{ secrets.SNOWFLAKE_ACCOUNT }}',
              warehouse='${{ secrets.SNOWFLAKE_WAREHOUSE }}',
              database='${{ secrets.SNOWFLAKE_DATABASE }}',
              schema='${{ secrets.SNOWFLAKE_SCHEMA }}'
          )
          # Execute the query
          query = 'Select GET_DDL(''Table'', ''DWH_CI_CD.CI_CD.CHANGE_HISTORY'',true)'
          df = pd.read_sql(query, conn)
          # Specify the folder path within the repository
          folder_path = 'Scripts'
          os.makedirs(folder_path, exist_ok=True)
          # Write to CSV, overwriting if it exists
          file_path = os.path.join(folder_path, 'CHANGE_HISTORY.sql')
          df.to_csv(file_path, index=False)
          conn.close()
          "

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add Scripts/CHANGE_HISTORY.sql
          git commit -m "Update data file from Snowflake" || echo "No changes to commit"
          git push
